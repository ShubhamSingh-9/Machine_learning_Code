{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daefb969",
   "metadata": {},
   "source": [
    "# How the coefficents get affacted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec073ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd472085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a34738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df['Target'] = data.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d100ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data.data,data.target,test_size = 0.1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4273a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,2].values \n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "plt.scatter(X, y)  # Use the third feature (column index 2) for x-axis\n",
    "plt.xlabel(\"Feature 2\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.title(\"Diabetes Dataset Scatter Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521660c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6525b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=[]\n",
    "r2=[]\n",
    "\n",
    "for i in [0,10,100,1000]:\n",
    "    reg = Ridge(alpha=i)\n",
    "    reg.fit(X_train,y_train)\n",
    "    coef.append(reg.coef_.tolist())\n",
    "    \n",
    "    y_predict = reg.predict(X_test)\n",
    "    r2.append(r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "plt.subplot(221)\n",
    "plt.bar(data.feature_names,coef[0])\n",
    "plt.title('Alpha =0, R2_score={}'.format(round(r2[0],2)))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.bar(data.feature_names,coef[1])\n",
    "plt.title('Alpha = 10, R2_score={}'.format(round(r2[1],2)))\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.bar(data.feature_names,coef[2])\n",
    "plt.title('Alpha = 100, R2_score={}'.format(round(r2[2],2)))\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.bar(data.feature_names,coef[3])\n",
    "plt.title('Alpha = 1000, R2_score={}'.format(round(r2[3],2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad185e7",
   "metadata": {},
   "source": [
    "# 2. Higher Coefficients are affected more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coefs = []\n",
    "\n",
    "for i in [0,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]:\n",
    "    reg = Ridge(alpha=i)\n",
    "    reg.fit(X_train,y_train)\n",
    "    \n",
    "    coefs.append(reg.coef_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.array(coefs)\n",
    "\n",
    "coef_df = pd.DataFrame(input_array,columns=data.feature_names)\n",
    "coef_df['alpha'] = [0,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "coef_df.set_index('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0,0.0001,0.0005,0.001,0.005,0.1,0.5,1,5,10]\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for i in alphas:\n",
    "    reg = Ridge(alpha=i)\n",
    "    reg.fit(X_train,y_train)\n",
    "    \n",
    "    coefs.append(reg.coef_.tolist())\n",
    "    \n",
    "    \n",
    "input_array = np.array(coefs).T\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(alphas,np.zeros(len(alphas)),color='black',linewidth=5)\n",
    "for i in range(input_array.shape[0]):\n",
    "    plt.plot(alphas,input_array[i],label=data.feature_names[i])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412b555",
   "metadata": {},
   "source": [
    "# 3. Impact on Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de526bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "X = 5 * np.random.rand(m, 1) - 2\n",
    "y = 0.7 * X ** 2 - 2 * X + 3 + np.random.randn(m, 1)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbe5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X.reshape(100,1),y.reshape(100),test_size=0.2,random_state=2)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=15)\n",
    "\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ebe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install mlxtend\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "alphas = np.linspace(0,30,100)\n",
    "\n",
    "loss = []\n",
    "bias = []\n",
    "variance = []\n",
    "\n",
    "for i in alphas:\n",
    "    reg = Ridge(alpha=i)\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        reg, X_train, y_train, X_test, y_test, \n",
    "        loss='mse',\n",
    "        random_seed=123)\n",
    "    loss.append(avg_expected_loss)\n",
    "    bias.append(avg_bias)\n",
    "    variance.append(avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas,loss,label='loss')\n",
    "plt.plot(alphas,bias,label='Bias')\n",
    "plt.plot(alphas,variance,label='Variance')\n",
    "plt.ylim(0,5)\n",
    "plt.xlabel('Alpha')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51f715",
   "metadata": {},
   "source": [
    "# 4. Effect of Regularization on Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X,y = make_regression(n_samples=100, n_features=1, n_informative=1, n_targets=1,noise=20,random_state=13)\n",
    "\n",
    "plt.scatter(X,y)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(m,alpha):\n",
    "    return np.sum((y - m*X.ravel() + 2.29)**2) + alpha*m*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(m):\n",
    "    return m*X - 2.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.linspace(-45,100,100)\n",
    "plt.figure(figsize=(4,6))\n",
    "for j in [0,10,20,30,40,50,100]:\n",
    "    loss = []\n",
    "    for i in range(m.shape[0]):\n",
    "        loss_i = cal_loss(m[i],j)\n",
    "        loss.append(loss_i)\n",
    "    plt.plot(m,loss,label='alpha = {}'.format(j))\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a19243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
